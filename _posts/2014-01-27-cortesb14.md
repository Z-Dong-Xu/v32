---
supplementary: Supplementary:cortesb14-supp.zip
title: Deep Boosting
abstract: We present a new ensemble learning algorithm, DeepBoost, which can use as
  base classifiers a hypothesis set containing deep decision trees, or members of
  other rich or complex families, and succeed in achieving high accuracy without overfitting
  the data. The key to the success of the algorithm is a ‘capacity-conscious’ criterion
  for the selection of the hypotheses.  We give new data-dependent learning bounds
  for convex ensembles expressed in terms of the Rademacher complexities of the sub-families
  composing the base classifier set, and the mixture weight assigned to each sub-family.
  Our algorithm directly benefits from these guarantees since it seeks to minimize
  the corresponding learning bound. We give a full description of our algorithm, including
  the details of its derivation, and report the results of several experiments showing
  that its performance compares favorably to that of AdaBoost and Logistic Regression
  and their L_1-regularized variants.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cortesb14
month: 0
firstpage: 1179
lastpage: 1187
page: 1179-1187
sections: 
author:
- given: Corinna
  family: Cortes
- given: Mehryar
  family: Mohri
- given: Umar
  family: Syed
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of The 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/cortesb14/cortesb14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
