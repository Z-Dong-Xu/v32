---
pdf: http://proceedings.mlr.press/v32/lin14/lin14.pdf
section: cycle-1
supplementary: Supplementary:lin14-supp.pdf
title: An Adaptive Accelerated Proximal Gradient Method and its Homotopy Continuation
  for Sparse Optimization
abstract: We first propose an adaptive accelerated proximal gradient(APG) method for
  minimizing strongly convex composite functions with unknown convexity parameters.
  This method incorporates a restarting scheme to automatically estimate the strong
  convexity parameter and achieves a nearly optimal iteration complexity. Then we
  consider the ℓ1-regularized least-squares (ℓ1-LS) problem in the high-dimensional
  setting. Although such an objective function is not strongly convex, it has restricted
  strong convexity over sparse vectors. We exploit this property by combining the
  adaptive  APG method with a homotopy continuation scheme, which generates a sparse
  solution path towards optimality. This method obtains a global linear rate of convergence
  and its overall iteration complexity has a weaker dependency on the restricted condition
  number than previous work.
layout: inproceedings
id: lin14
month: 0
firstpage: 73
lastpage: 81
page: 73-81
sections: 
author:
- given: Qihang
  family: Lin
- given: Lin
  family: Xiao
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of The 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
