---
supplementary: Supplementary:meng14-supp.zip
title: Learning Latent Variable Gaussian Graphical Models
abstract: Gaussian graphical models (GGM) have been widely used in many high-dimensional
  applications ranging from biological and financial data to recommender systems.
  Sparsity in GGM plays a central role both statistically and computationally. Unfortunately,
  real-world data often does not fit well to sparse graphical models.  In this paper,
  we focus on a family of latent variable Gaussian graphical models (LVGGM), where
  the model is conditionally sparse given latent variables, but marginally non-sparse.
  In LVGGM, the inverse covariance matrix has a low-rank plus sparse structure, and
  can be learned in a regularized maximum likelihood framework. We derive novel parameter
  estimation error bounds for LVGGM under mild conditions in the high-dimensional
  setting. These results complement the existing theory on the structural learning,
  and open up new possibilities of using LVGGM for statistical inference.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: meng14
month: 0
tex_title: Learning Latent Variable Gaussian Graphical Models
firstpage: 1269
lastpage: 1277
page: 1269-1277
sections: 
author:
- given: Zhaoshi
  family: Meng
- given: Brian
  family: Eriksson
- given: Al
  family: Hero
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/meng14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
