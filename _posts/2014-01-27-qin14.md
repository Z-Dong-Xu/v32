---
supplementary: Supplementary:qin14-supp.pdf
title: Sparse Reinforcement Learning via Convex Optimization
abstract: We propose two new algorithms for the sparse reinforcement learning problem
  based on different formulations.  The first algorithm is an off-line method based
  on the alternating direction method of multipliers for solving a constrained formulation
  that explicitly controls the projected Bellman residual.  The second algorithm is
  an online stochastic approximation algorithm that employs the regularized dual averaging
  technique, using the Lagrangian formulation.  The convergence of both algorithms
  are established. We demonstrate the performance of these algorithms through two
  classical examples.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: qin14
month: 0
firstpage: 424
lastpage: 432
page: 424-432
sections: 
author:
- given: Zhiwei
  family: Qin
- given: Weichang
  family: Li
- given: Firdaus
  family: Janoos
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/qin14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
