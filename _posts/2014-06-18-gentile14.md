---
supplementary: http://proceedings.mlr.press/v32/gentile14-supp.pdf
title: Online Clustering of Bandits
abstract: We introduce a novel algorithmic approach to content recommendation based
  on adaptive clustering of exploration-exploitation (â€œbandit") strategies. We provide
  a sharp regret analysis of this algorithm in a standard stochastic noise setting,
  demonstrate its scalability properties, and prove its effectiveness on a number
  of artificial and real-world datasets. Our experiments show a significant increase
  in prediction performance over state-of-the-art methods for bandit problems.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: gentile14
month: 0
tex_title: Online Clustering of Bandits
firstpage: 757
lastpage: 765
page: 757-765
order: 757
cycles: false
author:
- given: Claudio
  family: Gentile
- given: Shuai
  family: Li
- given: Giovanni
  family: Zappella
date: 2014-06-18
number: 2
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 6
  - 18
pdf: http://proceedings.mlr.press/v32/gentile14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
