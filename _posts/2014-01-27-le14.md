---
title: Distributed Representations of Sentences and Documents
abstract: 'Many machine learning algorithms require the  input to be represented as
  a fixed length feature  vector. When it comes to texts, one of the most  common
  representations is bag-of-words. Despite their popularity, bag-of-words models have  two
  major weaknesses: they lose the ordering  of the words and they also ignore semantics
  of  the words. For example, "powerful," "strong"  and "Paris" are equally distant.
  In this paper,  we propose an unsupervised algorithm that learns  vector representations
  of sentences and text documents. This algorithm represents each document by a dense
  vector which is trained to predict  words in the document. Its construction gives
  our  algorithm the potential to overcome the weaknesses of bag-of-words models.
  Empirical results show that our technique outperforms bag-of-words models as well
  as other techniques for  text representations. Finally, we achieve new  state-of-the-art
  results on several text classification and sentiment analysis tasks.'
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: le14
month: 0
firstpage: 1188
lastpage: 1196
page: 1188-1196
sections: 
author:
- given: Quoc
  family: Le
- given: Tomas
  family: Mikolov
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/le14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
