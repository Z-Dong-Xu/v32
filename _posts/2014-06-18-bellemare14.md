---
supplementary: http://proceedings.mlr.press/v32/bellemare14-supp.pdf
title: Skip Context Tree Switching
abstract: Context Tree Weighting (CTW) is a powerful probabilistic sequence prediction
  technique that efficiently performs Bayesian model averaging over the class of all
  prediction suffix trees of bounded depth. In this paper we show how to generalize
  this technique to the class of K-skip prediction suffix trees. Contrary to regular
  prediction suffix trees, K-skip prediction suffix trees are permitted to ignore
  up to K contiguous portions of the context. This allows for significant improvements
  in predictive accuracy when irrelevant variables are present, a case which often
  occurs within record-aligned data and images. We provide a regret-based analysis
  of our approach, and empirically evaluate it on the Calgary corpus and a set of
  Atari 2600 screen prediction tasks.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: bellemare14
month: 0
tex_title: Skip Context Tree Switching
firstpage: 1458
lastpage: 1466
page: 1458-1466
order: 1458
cycles: false
author:
- given: Marc
  family: Bellemare
- given: Joel
  family: Veness
- given: Erik
  family: Talvitie
date: 2014-06-18
number: 2
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 6
  - 18
pdf: http://proceedings.mlr.press/v32/bellemare14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
