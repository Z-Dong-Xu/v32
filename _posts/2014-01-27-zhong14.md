---
pdf: http://proceedings.mlr.press/v32/zhong14.pdf
section: cycle-1
title: Fast Stochastic Alternating Direction Method of Multipliers
abstract: We propose a new stochastic alternating direction method of multipliers
  (ADMM) algorithm, which incrementally approximates the full gradient in the linearized
  ADMM formulation. Besides having a low per-iteration complexity as existing stochastic
  ADMM algorithms,  it improves the convergence rate on convex problems from \mO(1/\sqrtT)
  to \mO(1/T), where T is the number of iterations. This matches the  convergence
  rate of the batch ADMM algorithm, but without the need to visit all the samples
  in each iteration. Experiments on the graph-guided fused lasso demonstrate that
  the new algorithm is significantly faster than state-of-the-art stochastic and batch
  ADMM algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zhong14
month: 0
tex_title: Fast Stochastic Alternating Direction Method of Multipliers
firstpage: 46
lastpage: 54
page: 46-54
order: 46
cycles: false
author:
- given: Wenliang
  family: Zhong
- given: James
  family: Kwok
date: 2014-01-27
number: 1
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
