---
title: 'Least Squares Revisited: Scalable Approaches for Multi-class Prediction'
abstract: This work provides simple algorithms for multi-class (and multi-label) prediction
  in settings where both the number of examples n and the data dimension d are relatively    large.
  These robust and parameter free algorithms are essentially    iterative least-squares
  updates and very versatile both in theory and in practice. On the theoretical front,
  we present several variants with convergence guarantees. Owing to their effective
  use of second-order structure, these algorithms are substantially better than first-order
  methods in many practical scenarios. On the empirical side, we show how to scale
  our approach to high dimensional datasets, achieving dramatic computational speedups
  over popular optimization packages such as Liblinear and Vowpal Wabbit on standard
  datasets (MNIST and CIFAR-10), while attaining state-of-the-art accuracies.
section: cycle-2
layout: inproceedings
id: agarwala14
month: 0
firstpage: 541
lastpage: 549
page: 541-549
sections: 
author:
- given: Alekh
  family: Agarwal
- given: Sham
  family: Kakade
- given: Nikos
  family: Karampatziakis
- given: Le
  family: Song
- given: Gregory
  family: Valiant
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of The 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/agarwala14/agarwala14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
