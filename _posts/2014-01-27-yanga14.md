---
pdf: http://proceedings.mlr.press/v32/yanga14/yanga14.pdf
section: cycle-1
supplementary: Supplementary:yanga14-supp.pdf
title: The Coherent Loss Function for Classification
abstract: A prediction rule in binary classification that aims to achieve the lowest
  probability of misclassification involves minimizing over a non-convex, 0-1 loss
  function, which is typically a computationally intractable optimization problem.
  To address the intractability, previous methods consider minimizing the cumulative
  loss â€“ the sum of convex surrogates of the 0-1 loss of each sample. In this paper,
  we revisit this paradigm and develop instead an axiomatic framework by proposing
  a set of salient properties on functions for binary classification and then propose
  the coherent loss approach, which is a tractable upper-bound of the empirical classification
  error over the entire sample set. We show that the proposed approach yields a strictly
  tighter approximation to the empirical classification error than any convex cumulative
  loss approach while preserving the convexity of the underlying optimization problem,
  and this approach for binary classification also has a robustness interpretation
  which builds a connection to robust SVMs. The experimental results show that our
  approach outperforms the standard SVM when additional constraints are imposed.
layout: inproceedings
id: yanga14
month: 0
firstpage: 37
lastpage: 45
page: 37-45
sections: 
author:
- given: Wenzhuo
  family: Yang
- given: Melvyn
  family: Sim
- given: Huan
  family: Xu
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of The 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
