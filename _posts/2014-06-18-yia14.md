---
supplementary: http://proceedings.mlr.press/v32/yia14-supp.pdf
title: Alternating Minimization for Mixed Linear Regression
abstract: Mixed linear regression involves the recovery of two (or more) unknown vectors
  from unlabeled linear measurements; that is, where each sample comes from exactly
  one of the vectors, but we do not know which one. It is a classic problem, and the
  natural and empirically most popular approach to its solution has been the EM algorithm.
  As in other settings, this is prone to bad local minima; however, each iteration
  is very fast (alternating between guessing labels, and solving with those labels).    In
  this paper we provide a new initialization procedure for EM, based on finding the
  leading two eigenvectors of an appropriate matrix. We then show that with this,
  a re-sampled version of the EM algorithm provably converges to the correct vectors,
  under natural assumptions on the sampling distribution, and with nearly optimal
  (unimprovable) sample complexity. This provides not only the first characterization
  of EMâ€™s performance, but also much lower sample complexity as compared to both standard
  (randomly initialized) EM, and other methods for this problem.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: yia14
month: 0
tex_title: Alternating Minimization for Mixed Linear Regression
firstpage: 613
lastpage: 621
page: 613-621
order: 613
cycles: false
author:
- given: Xinyang
  family: Yi
- given: Constantine
  family: Caramanis
- given: Sujay
  family: Sanghavi
date: 2014-06-18
number: 2
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 6
  - 18
pdf: http://proceedings.mlr.press/v32/yia14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
