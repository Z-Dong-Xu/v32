---
supplementary: Supplementary:honorio14-supp.pdf
title: A Unified Framework for Consistency of Regularized Loss Minimizers
abstract: 'We characterize a family of regularized loss minimization problems that
  satisfy three properties: scaled uniform convergence, super-norm regularization,
  and norm-loss monotonicity. We show several theoretical guarantees within this framework,
  including loss consistency, norm consistency, sparsistency (i.e. support recovery)
  as well as sign consistency. A number of regularization problems can be shown to
  fall within our framework and we provide several examples. Our results can be seen
  as a concise summary of existing guarantees but we also extend them to new settings.
  Our formulation enables us to assume very little about the hypothesis class, data
  distribution, the loss, or the regularization. In particular, many of our results
  do not require a bounded hypothesis class, or identically distributed samples. Similarly,
  we do not assume boundedness, convexity or smoothness of the loss nor the regularizer.
  We only assume approximate optimality of the empirical minimizer. In terms of recovery,
  in contrast to existing results, our sparsistency and sign consistency results do
  not require knowledge of the sub-differential of the objective function.'
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: honorio14
month: 0
tex_title: A Unified Framework for Consistency of Regularized Loss Minimizers
firstpage: 136
lastpage: 144
page: 136-144
sections: 
author:
- given: Jean
  family: Honorio
- given: Tommi
  family: Jaakkola
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/honorio14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
