---
supplementary: Supplementary:levine14-supp.zip
title: Learning Complex Neural Network Policies with Trajectory Optimization
abstract: Direct policy search methods offer the promise of automatically learning
  controllers for complex, high-dimensional tasks. However, prior applications of
  policy search often required specialized, low-dimensional policy classes, limiting
  their generality. In this work, we introduce a policy search algorithm that can
  directly learn high-dimensional, general-purpose policies, represented by neural
  networks. We formulate the policy search problem as an optimization over trajectory
  distributions, alternating between optimizing the policy to match the trajectories,
  and optimizing the trajectories to match the policy and minimize expected cost.
  Our method can learn policies for complex tasks such as bipedal push recovery and
  walking on uneven terrain, while outperforming prior methods.
section: cycle-2
layout: inproceedings
id: levine14
month: 0
firstpage: 829
lastpage: 837
page: 829-837
sections: 
author:
- given: Sergey
  family: Levine
- given: Vladlen
  family: Koltun
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of The 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/levine14/levine14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
