---
title: A Clockwork RNN
abstract: 'Sequence prediction and classification are ubiquitous and challenging problems
  in machine learning that can require identifying complex dependencies between temporally
  distant inputs. Recurrent Neural Networks (RNNs) have the ability, in theory, to
  cope with these temporal dependencies by virtue of the short-term memory implemented
  by their recurrent (feedback) connections. However, in practice they are difficult
  to train successfully when long-term memory is  required.    This paper introduces
  a simple, yet powerful modification to the  simple RNN (SRN) architecture, the Clockwork
  RNN (CW-RNN), in which the hidden layer is partitioned into separate modules, each
  processing inputs at its own temporal granularity, making computations only at its
  prescribed clock rate.    Rather than making the standard RNN models more complex,
  CW-RNN  reduces the number of SRN parameters, improves the performance  significantly
  in the tasks tested, and speeds up the network evaluation.    The network is demonstrated
  in preliminary experiments involving three tasks: audio signal generation, TIMIT
  spoken word classification,  where it outperforms both SRN and LSTM networks, and
  online handwriting recognition, where it outperforms SRNs.'
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: koutnik14
month: 0
tex_title: A Clockwork RNN
firstpage: 1863
lastpage: 1871
page: 1863-1871
sections: 
author:
- given: Jan
  family: Koutnik
- given: Klaus
  family: Greff
- given: Faustino
  family: Gomez
- given: Juergen
  family: Schmidhuber
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/koutnik14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
