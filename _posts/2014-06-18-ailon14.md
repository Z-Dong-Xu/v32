---
supplementary: http://proceedings.mlr.press/v32/ailon14-supp.zip
title: Reducing Dueling Bandits to Cardinal Bandits
abstract: We present algorithms for reducing the Dueling Bandits problem to the conventional
  (stochastic) Multi-Armed Bandits problem. The Dueling Bandits problem is an online
  model of learning with ordinal feedback of the form “A is preferred to B” (as opposed
  to cardinal feedback like “A has value 2.5”), giving it wide applicability in learning
  from implicit user feedback and revealed and stated preferences. In contrast to
  existing algorithms for the Dueling Bandits problem, our reductions – named \Doubler,
  \MultiSbm and \DoubleSbm – provide a generic schema for translating the extensive
  body of known results about conventional Multi-Armed Bandit algorithms to the Dueling
  Bandits setting.     For \Doubler and \MultiSbm we prove regret upper bounds in
  both finite and infinite settings, and conjecture about the performance of \DoubleSbm
  which empirically outperforms the other two as well as previous algorithms in our
  experiments.  In addition, we provide the first almost optimal regret bound in terms
  of second order terms, such as the differences between the values of the arms.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: ailon14
month: 0
tex_title: Reducing Dueling Bandits to Cardinal Bandits
firstpage: 856
lastpage: 864
page: 856-864
order: 856
cycles: false
author:
- given: Nir
  family: Ailon
- given: Zohar
  family: Karnin
- given: Thorsten
  family: Joachims
date: 2014-06-18
number: 2
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 6
  - 18
pdf: http://proceedings.mlr.press/v32/ailon14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
