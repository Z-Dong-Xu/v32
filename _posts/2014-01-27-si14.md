---
pdf: http://proceedings.mlr.press/v32/si14/si14.pdf
section: cycle-1
supplementary: Supplementary:si14-supp.pdf
title: Memory Efficient Kernel Approximation
abstract: The scalability of kernel machines is a big challenge when facing millions
  of samples due to storage and computation issues for large kernel matrices, that
  are usually dense. Recently, many papers have suggested tackling this problem by
  using a low rank approximation of the kernel matrix. In this paper, we first make
  the observation that the structure of shift-invariant kernels changes from low-rank
  to block-diagonal (without any low-rank structure) when varying the scale parameter.
  Based on this observation, we propose a new kernel approximation algorithm – Memory
  Efficient Kernel Approximation (MEKA), which considers both low-rank and clustering
  structure of the kernel matrix. We show that the resulting algorithm outperforms
  state-of-the-art low-rank kernel approximation methods in terms of speed, approximation
  error, and memory usage. As an example, on the MNIST2M dataset with two-million
  samples, our method takes 550 seconds on a single machine using less than 500 MBytes
  memory to achieve 0.2313 test RMSE for kernel ridge regression, while standard Nyström
  approximation takes more than 2700 seconds and uses more than 2 GBytes memory on
  the same problem to achieve 0.2318 test RMSE.
layout: inproceedings
id: si14
month: 0
firstpage: 701
lastpage: 709
page: 701-709
sections: 
author:
- given: Si
  family: Si
- given: Cho-Jui
  family: Hsieh
- given: Inderjit
  family: Dhillon
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of The 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
