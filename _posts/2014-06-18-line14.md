---
title: Stable and Efficient Representation Learning with Nonnegativity Constraints
abstract: Orthogonal matching pursuit (OMP) is an efficient approximation algorithm
  for computing sparse representations. However, prior research has shown that the
  representations computed by OMP may be of inferior quality, as they deliver suboptimal
  classification accuracy on several im- age datasets. We have found that this problem
  is caused by OMP’s relatively weak stability under data variations, which leads
  to unreliability in supervised classifier training. We show that by imposing a simple
  nonnegativity constraint, this nonnegative variant of OMP (NOMP) can mitigate OMP’s
  stability issue and is resistant to noise overfitting. In this work, we provide
  extensive analysis and experimental results to examine and validate the stability
  advantage of NOMP. In our experiments, we use a multi-layer deep architecture for
  representation learning, where we use K-means for feature learning and NOMP for
  representation encoding. The resulting learning framework is not only efficient
  and scalable to large feature dictionaries, but also is robust against input noise.
  This framework achieves the state-of-the-art accuracy on the STL-10 dataset.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: line14
month: 0
tex_title: Stable and Efficient Representation Learning with Nonnegativity Constraints
firstpage: 1323
lastpage: 1331
page: 1323-1331
order: 1323
cycles: false
author:
- given: Tsung-Han
  family: Lin
- given: H. T.
  family: Kung
date: 2014-06-18
number: 2
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 6
  - 18
pdf: http://proceedings.mlr.press/v32/line14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
