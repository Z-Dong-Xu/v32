---
title: Stochastic Variational Inference for Bayesian Time Series Models
abstract: Bayesian models provide powerful tools for analyzing complex time series
  data, but performing inference with large datasets is a challenge.  Stochastic variational
  inference (SVI) provides a new framework for approximating model posteriors with
  only a small number of passes through the data, enabling such models to be fit at
  scale.  However, its application to time series models has not been studied.    In
  this paper we develop SVI algorithms for several common Bayesian time series models,
  namely the hidden Markov model (HMM), hidden semi-Markov model (HSMM), and the nonparametric
  HDP-HMM and HDP-HSMM.  In addition, because HSMM inference can be expensive even
  in the minibatch setting of SVI, we develop fast approximate updates for HSMMs with
  durations distributions that are negative binomials or mixtures of negative binomials.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: johnson14
month: 0
tex_title: Stochastic Variational Inference for Bayesian Time Series Models
firstpage: 1854
lastpage: 1862
page: 1854-1862
sections: 
author:
- given: Matthew
  family: Johnson
- given: Alan
  family: Willsky
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/johnson14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
