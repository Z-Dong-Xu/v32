---
pdf: http://proceedings.mlr.press/v32/yangb14.pdf
section: cycle-1
supplementary: Supplementary:yangb14-supp.pdf
title: Quasi-Monte Carlo Feature Maps for Shift-Invariant Kernels
abstract: We consider the problem of improving the efficiency of randomized Fourier
  feature maps to accelerate training and testing speed of kernel methods on large
  datasets. These approximate feature maps arise as Monte Carlo approximations to
  integral representations of shift-invariant kernel functions (e.g., Gaussian kernel).
  In this paper, we propose to use Quasi-Monte Carlo (QMC) approximations instead  where
  the relevant integrands are evaluated on a low-discrepancy sequence of points as
  opposed to random point sets as in the Monte Carlo approach. We derive a new discrepancy
  measure called box discrepancy based on theoretical characterizations of the integration
  error with respect to a given sequence. We then propose to learn QMC sequences adapted
  to our setting based on explicit box discrepancy minimization. Our theoretical analyses
  are complemented with empirical results that demonstrate the effectiveness of classical
  and adaptive QMC techniques for this problem.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: yangb14
month: 0
tex_title: Quasi-Monte Carlo Feature Maps for Shift-Invariant Kernels
firstpage: 485
lastpage: 493
page: 485-493
sections: 
author:
- given: Jiyan
  family: Yang
- given: Vikas
  family: Sindhwani
- given: Haim
  family: Avron
- given: Michael
  family: Mahoney
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
