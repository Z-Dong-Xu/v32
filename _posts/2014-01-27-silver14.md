---
pdf: http://proceedings.mlr.press/v32/silver14.pdf
section: cycle-1
supplementary: http://proceedings.mlr.press/v32/silver14-supp.pdf
title: Deterministic Policy Gradient Algorithms
abstract: 'In this paper we consider deterministic policy gradient algorithms for
  reinforcement learning with continuous actions. The deterministic policy gradient
  has a particularly appealing form: it is the expected gradient of the action-value
  function. This simple form means that the deterministic policy gradient can be estimated
  much more efficiently than the usual stochastic policy gradient. To ensure adequate
  exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic
  target policy from an exploratory behaviour policy. Deterministic policy gradient
  algorithms outperformed their stochastic counterparts in several benchmark problems,
  particularly in high-dimensional action spaces.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: silver14
month: 0
tex_title: Deterministic Policy Gradient Algorithms
firstpage: 387
lastpage: 395
page: 387-395
order: 387
cycles: false
author:
- given: David
  family: Silver
- given: Guy
  family: Lever
- given: Nicolas
  family: Heess
- given: Thomas
  family: Degris
- given: Daan
  family: Wierstra
- given: Martin
  family: Riedmiller
date: 2014-01-27
number: 1
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
