---
supplementary: Supplementary:suna14-supp.pdf
title: An Information Geometry of Statistical Manifold Learning
abstract: Manifold learning seeks low-dimensional representations of high-dimensional
  data. The main tactics have been exploring the geometry in an input data space and
  an output embedding space. We develop a manifold learning theory in a hypothesis
  space consisting of models. A model means a specific instance of a collection of
  points, e.g., the input data collectively or the output embedding collectively.
  The semi-Riemannian metric of this hypothesis space is uniquely derived in closed
  form based on the information geometry of probability distributions. There, manifold
  learning is interpreted as a trajectory of intermediate models. The volume of a
  continuous region reveals an amount of information. It can be measured to define
  model complexity and embedding quality. This provides deep unified perspectives
  of manifold learning theory.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: suna14
month: 0
firstpage: 1
lastpage: 9
page: 1-9
sections: 
author:
- given: Ke
  family: Sun
- given: St√©phane
  family: Marchand-Maillet
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of The 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/suna14/suna14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
