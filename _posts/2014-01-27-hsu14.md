---
title: Heavy-tailed regression with a generalized median-of-means
abstract: This work proposes a simple and computationally efficient estimator for  linear
  regression, and other smooth and strongly convex loss minimization  problems.  We
  prove loss approximation guarantees that hold for general distributions,  including
  those with heavy tails. All prior results only hold for estimators which  either
  assume bounded or subgaussian distributions,  require prior knowledge of distributional
  properties, or are not known to be computationally tractable.  In the special case
  of linear regression with possibly heavy-tailed responses and with bounded and well-conditioned
  covariates in d-dimensions, we show that a random sample of size  \tildeO(d\log(1/δ))
  suffices to obtain a constant factor  approximation to the optimal loss with probability
  1-δ, a minimax optimal sample complexity up to log factors.  The core technique
  used in the proposed estimator is a new generalization of  the median-of-means estimator
  to arbitrary metric spaces.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hsu14
month: 0
firstpage: 37
lastpage: 45
page: 37-45
sections: 
author:
- given: Daniel
  family: Hsu
- given: Sivan
  family: Sabato
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/hsu14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
