---
supplementary: Supplementary:azar14-supp.zip
title: Online Stochastic Optimization  under Correlated Bandit Feedback
abstract: In this paper we consider the problem of online stochastic optimization
  of a locally smooth function under bandit feedback. We introduce the high-confidence
  tree (HCT) algorithm, a novel anytime \mathcal X-armed bandit algorithm, and derive
  regret bounds matching the performance of state-of-the-art algorithms in terms of
  the dependency on number of steps and the near-optimality dimension. The main advantage
  of HCT is that it handles the challenging case of correlated bandit feedback (reward),
  whereas existing methods require rewards to be conditionally independent. HCT also
  improves on the state-of-the-art in terms of the memory requirement, as well as
  requiring a weaker smoothness assumption on the mean-reward function in comparison
  with the existing anytime algorithms. Finally, we discuss how HCT can be applied
  to the problem of policy search in reinforcement learning and we report preliminary
  empirical results.
section: cycle-2
layout: inproceedings
series: Proceedings of Machine Learning Research
id: azar14
month: 0
firstpage: 1557
lastpage: 1565
page: 1557-1565
sections: 
author:
- given: Mohammad Gheshlaghi
  family: azar
- given: Alessandro
  family: Lazaric
- given: Emma
  family: Brunskill
date: 2014-01-27
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
pdf: http://proceedings.mlr.press/v32/azar14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
