---
pdf: http://proceedings.mlr.press/v32/denis14.pdf
section: cycle-1
title: Dimension-free Concentration Bounds on Hankel Matrices for Spectral Learning
abstract: Learning probabilistic models over strings is an important issue for many
  applications. Spectral methods propose elegant solutions to the problem of inferring
  weighted automata from finite samples of variable-length strings drawn from an unknown
  target distribution. These methods rely on a singular value decomposition of a matrix
  H_S, called the Hankel matrix, that records the frequencies of (some of) the observed
  strings. The accuracy of the learned distribution depends both on the quantity of
  information embedded in H_S and on the distance between H_S and its mean H_r. Existing
  concentration bounds seem to indicate that the concentration over H_r gets looser
  with its size, suggesting to make a trade-off between the quantity of used information
  and the size of H_r. We propose new dimension-free concentration bounds for several
  variants of Hankel matrices. Experiments demonstrate that these bounds are tight
  and that they significantly improve existing bounds. These results suggest that
  the concentration rate of the Hankel matrix around its mean does not constitute
  an argument for limiting its size.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: denis14
month: 0
tex_title: Dimension-free Concentration Bounds on Hankel Matrices for Spectral Learning
firstpage: 449
lastpage: 457
page: 449-457
order: 449
cycles: false
author:
- given: Fran√ßois
  family: Denis
- given: Mattias
  family: Gybels
- given: Amaury
  family: Habrard
date: 2014-01-27
number: 1
address: Bejing, China
publisher: PMLR
container-title: Proceedings of the 31st International Conference on Machine Learning
volume: '32'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 1
  - 27
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
